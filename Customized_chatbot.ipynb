{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e455cc26-b122-4790-9345-9ceaa26fd0ee",
   "metadata": {},
   "source": [
    "#### Install the required libraries \n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db922d7-a2b2-4dbd-8dac-ffa49c026693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (2023.5.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.1.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (1.4.49)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (0.0.34)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (0.1.45)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (0.1.49)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain_community in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.0.34)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (1.4.49)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.45 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (0.1.45)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (0.1.49)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.45->langchain_community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.45->langchain_community) (1.10.12)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2023.7.22)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain_community) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain_community) (4.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pymupdf in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.24.2)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pymupdf) (1.24.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: faiss-cpu in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from faiss-cpu) (1.24.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install pymupdf\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11ef6b-0a48-4aec-9854-e2d3f98e3149",
   "metadata": {},
   "source": [
    "\n",
    "#### Import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ab1807-48c2-48c0-8443-41a078c79710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import Replicate\n",
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580b5f47-0f16-410f-96ef-c31f4f5d2ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Document Loading \n",
    "#Load the directory that has domain specific documents\n",
    "dir_loader = DirectoryLoader('Dataset/', \n",
    "                             glob=\"**/*.pdf\", \n",
    "                             show_progress=True, use_multithreading=True,\n",
    "                             loader_cls=PyMuPDFLoader)\n",
    "\n",
    "data = dir_loader.load()\n",
    "\n",
    "#Document Transformation\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5244a188-acfe-41c2-b096-ec95351d93db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 0, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}\n",
      "Evaluating AI for Law: Bridging the Gap with\n",
      "Open-Source Solutions\n",
      "Rohan Bhambhoria1,2[0000−0002−2597−670X],\n",
      "Samuel Dahan1,2,3[0000−0002−1079−8998],\n",
      "Jonathan Li2[0000−0002−7095−805X], and\n",
      "Xiaodan Zhu1,2[0000−0003−3856−3696]\n",
      "1 Queen’s University, Kingston ON K7L3N6, Canada\n",
      "{r.bhambhoria, samuel.dahan, jxl, xiaodan.zhu}@queensu.ca\n",
      "2 Ingenuity Labs\n",
      "3 Cornell University\n",
      "Abstract. This study evaluates the performance of general-purpose AI,\n",
      "like ChatGPT, in legal question-answering tasks, highlighting significant\n",
      "risks to legal professionals and clients. It suggests leveraging founda-\n",
      "tional models enhanced by domain-specific knowledge to overcome these\n",
      "issues. The paper advocates for creating open-source legal AI systems\n",
      "to improve accuracy, transparency, and narrative diversity, addressing\n",
      "general AI’s shortcomings in legal contexts.\n",
      "Keywords: Law · Open-Source · Large Language Models.\n",
      "1\n",
      "Introduction\n",
      "In recent times, the rise of Large Language Models (LLMs) has become promi-\n",
      "nent, especially with the unprecedented growth of ChatGPT, marking it as the\n",
      "fastest-expanding consumer application to date. LLMs have shown extensive\n",
      "utility in tasks related to productivity and in systems designed for low-stakes\n",
      "decision-making, such as composing emails. However, its application in high-\n",
      "stakes decision-making areas, including contract drafting or medical diagnostics,\n",
      "is met with cautious adaptation due to concerns about its large-scale deploy-\n"
     ]
    }
   ],
   "source": [
    "#Check the splitted document sample\n",
    "print(docs[0].metadata)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b2fe3b-d052-4e21-ac1e-faf31d853e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using HuggingFace's BGE Embedding model \n",
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "                        \tmodel_name=\"BAAI/bge-small-en-v1.5\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" \n",
    "                                                                  # for a light and faster experience.\n",
    "                        \tmodel_kwargs={'device': 'cpu'},\n",
    "                        \tencode_kwargs={'normalize_embeddings': True} \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2443bbd3-bfa6-47d6-8b39-ed949ee7fc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04916955903172493,\n",
       " 0.0363210029900074,\n",
       " 0.010675057768821716,\n",
       " 0.020139532163739204,\n",
       " -0.02208401821553707,\n",
       " 0.009389788843691349,\n",
       " 0.03015921451151371,\n",
       " 0.05626610293984413,\n",
       " -0.0009100144379772246,\n",
       " -0.03351806849241257,\n",
       " -0.016063209623098373,\n",
       " -0.024940671399235725,\n",
       " 0.016899123787879944,\n",
       " 0.030053798109292984,\n",
       " 0.005090599413961172,\n",
       " -0.007806930225342512,\n",
       " -0.0032484543044120073,\n",
       " 0.002750767394900322,\n",
       " -0.023655923083424568,\n",
       " 0.028179416432976723,\n",
       " 0.027786096557974815,\n",
       " 0.03960951045155525,\n",
       " 0.012235529720783234,\n",
       " -0.01770024187862873,\n",
       " 0.0031805322505533695,\n",
       " 0.041944511234760284,\n",
       " 0.05696551501750946,\n",
       " -0.05506322160363197,\n",
       " -0.03417317941784859,\n",
       " -0.12369446456432343,\n",
       " -0.016410015523433685,\n",
       " -0.02873205952346325,\n",
       " 0.019709547981619835,\n",
       " 0.016292748972773552,\n",
       " 0.017873598262667656,\n",
       " -0.0013450781116262078,\n",
       " 0.0017727789236232638,\n",
       " 0.013763399794697762,\n",
       " 0.011978093534708023,\n",
       " -0.002964153653010726,\n",
       " 0.039542991667985916,\n",
       " -0.004725602455437183,\n",
       " -0.038533128798007965,\n",
       " 0.018712051212787628,\n",
       " -0.015966933220624924,\n",
       " 0.03282482549548149,\n",
       " 0.0344795286655426,\n",
       " -0.06218751147389412,\n",
       " 0.011635220609605312,\n",
       " 0.004308763425797224,\n",
       " -0.05813468620181084,\n",
       " -0.05119234323501587,\n",
       " -0.011253997683525085,\n",
       " -0.01642066240310669,\n",
       " -0.02944810502231121,\n",
       " -0.008105521090328693,\n",
       " 0.07474160194396973,\n",
       " 0.04804230108857155,\n",
       " 0.048191044479608536,\n",
       " 0.015570546500384808,\n",
       " -0.00046590162673965096,\n",
       " 0.01519938837736845,\n",
       " -0.1503833830356598,\n",
       " 0.08280251175165176,\n",
       " 0.045170001685619354,\n",
       " 0.04264621436595917,\n",
       " -0.0434267483651638,\n",
       " 0.0100791547447443,\n",
       " 0.011931705288589,\n",
       " 0.05127865448594093,\n",
       " 0.0012223965022712946,\n",
       " -0.014689735136926174,\n",
       " -0.06949220597743988,\n",
       " 0.1307903677225113,\n",
       " 0.00889087375253439,\n",
       " 0.022052690386772156,\n",
       " -0.01945776306092739,\n",
       " -0.04979284107685089,\n",
       " 0.0620754137635231,\n",
       " -0.053453363478183746,\n",
       " -0.056410323828458786,\n",
       " 0.001067619421519339,\n",
       " 0.05205414816737175,\n",
       " 0.03701974079012871,\n",
       " -0.010987458750605583,\n",
       " -0.06175544485449791,\n",
       " -0.01182299479842186,\n",
       " 0.06155126169323921,\n",
       " 0.03803037852048874,\n",
       " -0.016572099179029465,\n",
       " 0.013362424448132515,\n",
       " -0.006284345872700214,\n",
       " -0.014742454513907433,\n",
       " 0.04184470325708389,\n",
       " -0.039183590561151505,\n",
       " -0.05535980686545372,\n",
       " 0.0006714797927998006,\n",
       " -0.01978704333305359,\n",
       " 0.00944510567933321,\n",
       " 0.414216548204422,\n",
       " -0.019793452695012093,\n",
       " 0.023026349022984505,\n",
       " 0.005671279039233923,\n",
       " -0.028785014525055885,\n",
       " -0.0205158069729805,\n",
       " -0.014281683601439,\n",
       " 0.025995789095759392,\n",
       " -0.010755207389593124,\n",
       " -0.05215286836028099,\n",
       " -0.022807473316788673,\n",
       " 0.03239269554615021,\n",
       " -0.0336078517138958,\n",
       " 0.01649371162056923,\n",
       " -0.040448907762765884,\n",
       " -0.053098566830158234,\n",
       " 0.012274764478206635,\n",
       " 0.028860893100500107,\n",
       " 0.00826497282832861,\n",
       " -0.019968824461102486,\n",
       " -0.023146549239754677,\n",
       " -0.03888455033302307,\n",
       " 0.00995869841426611,\n",
       " 0.014907477423548698,\n",
       " -0.08279187977313995,\n",
       " 0.06259731948375702,\n",
       " -0.061097439378499985,\n",
       " 0.043644875288009644,\n",
       " 0.09091740101575851,\n",
       " -0.046503327786922455,\n",
       " -0.017921093851327896,\n",
       " -0.006257329601794481,\n",
       " -0.05266045033931732,\n",
       " -0.050310563296079636,\n",
       " 0.026863137260079384,\n",
       " -0.011527490802109241,\n",
       " 0.011542688123881817,\n",
       " -0.01611013524234295,\n",
       " -0.02774418517947197,\n",
       " -0.020359568297863007,\n",
       " 0.04848590865731239,\n",
       " -0.03792000561952591,\n",
       " -0.01760801486670971,\n",
       " 0.019488999620079994,\n",
       " -0.08408772945404053,\n",
       " -0.07942300289869308,\n",
       " 0.061372991651296616,\n",
       " 0.0022444624919444323,\n",
       " 0.0399395227432251,\n",
       " -0.04217379912734032,\n",
       " -0.07591485977172852,\n",
       " 0.03366904705762863,\n",
       " 0.06955145299434662,\n",
       " -0.01127484068274498,\n",
       " -0.031013112515211105,\n",
       " 0.008572599850594997,\n",
       " 0.0318421833217144,\n",
       " 0.09234531223773956,\n",
       " 0.0018918447894975543,\n",
       " 0.010697462595999241,\n",
       " 0.00894150324165821,\n",
       " -0.009659581817686558,\n",
       " -0.0020744754001498222,\n",
       " -0.07890833169221878,\n",
       " 0.0862254798412323,\n",
       " -0.0026447151321917772,\n",
       " -0.017955254763364792,\n",
       " -0.023859059438109398,\n",
       " -0.016911212354898453,\n",
       " -0.014375773258507252,\n",
       " -0.03652665391564369,\n",
       " 0.060302868485450745,\n",
       " 0.013073367066681385,\n",
       " -0.0787176713347435,\n",
       " 0.014056586660444736,\n",
       " -0.018178651109337807,\n",
       " -0.052247464656829834,\n",
       " -0.01972745545208454,\n",
       " 0.037238966673612595,\n",
       " 0.005767240654677153,\n",
       " 0.013424844481050968,\n",
       " 0.029244439676404,\n",
       " -0.03301024064421654,\n",
       " -0.03483652323484421,\n",
       " 0.031005553901195526,\n",
       " 0.01556440070271492,\n",
       " -0.02117166854441166,\n",
       " -0.035336658358573914,\n",
       " -0.021879417821764946,\n",
       " 0.0304853692650795,\n",
       " 0.017959870398044586,\n",
       " 0.0006363192806020379,\n",
       " -0.0621810145676136,\n",
       " -0.07981452345848083,\n",
       " 0.017493875697255135,\n",
       " -0.024935293942689896,\n",
       " -0.015341932885348797,\n",
       " 0.01637674681842327,\n",
       " -0.014424644410610199,\n",
       " -0.04210641607642174,\n",
       " -0.026068193838000298,\n",
       " 0.04265478253364563,\n",
       " 0.004578795284032822,\n",
       " 0.017867105081677437,\n",
       " 0.022364512085914612,\n",
       " -0.033233556896448135,\n",
       " 0.037690650671720505,\n",
       " 0.031069127842783928,\n",
       " -0.07472959160804749,\n",
       " 0.09237473458051682,\n",
       " -0.015629474073648453,\n",
       " -0.06756890565156937,\n",
       " -0.01030315738171339,\n",
       " 0.042904216796159744,\n",
       " 0.021599330008029938,\n",
       " -0.005409632343798876,\n",
       " -0.06556625664234161,\n",
       " 0.017771316692233086,\n",
       " -0.0011214781552553177,\n",
       " 0.013411822728812695,\n",
       " 0.083544060587883,\n",
       " -0.04286561161279678,\n",
       " -0.052584100514650345,\n",
       " -0.019298773258924484,\n",
       " -0.30069684982299805,\n",
       " -0.04989857226610184,\n",
       " -0.008184782229363918,\n",
       " 0.07250837981700897,\n",
       " 0.05786977335810661,\n",
       " -0.021273715421557426,\n",
       " -0.025757232680916786,\n",
       " 0.04743361100554466,\n",
       " -0.017733007669448853,\n",
       " 0.01938267983496189,\n",
       " 0.04175611585378647,\n",
       " -0.026035716757178307,\n",
       " -0.013541667722165585,\n",
       " -0.011842423118650913,\n",
       " 0.02455942891538143,\n",
       " -0.031153826043009758,\n",
       " 0.0026477233041077852,\n",
       " -0.002457959810271859,\n",
       " 0.01099091861397028,\n",
       " 0.015239957720041275,\n",
       " 0.004312917124480009,\n",
       " 0.001171476673334837,\n",
       " 0.05261671170592308,\n",
       " -0.08133704215288162,\n",
       " 0.009006199426949024,\n",
       " -0.0505126491189003,\n",
       " 0.17722462117671967,\n",
       " 0.0066722361370921135,\n",
       " -0.0059869056567549706,\n",
       " -0.027118206024169922,\n",
       " 0.0552697628736496,\n",
       " -0.008238342590630054,\n",
       " -0.0036144384648650885,\n",
       " -0.10208155959844589,\n",
       " 0.021288951858878136,\n",
       " 0.004409254994243383,\n",
       " -0.10848486423492432,\n",
       " 0.07804528623819351,\n",
       " -0.06339110434055328,\n",
       " -0.037611138075590134,\n",
       " 0.030432313680648804,\n",
       " 0.0072976467199623585,\n",
       " -0.06799902021884918,\n",
       " -0.0037000516895204782,\n",
       " 0.012539568357169628,\n",
       " -0.03235270082950592,\n",
       " 0.026575986295938492,\n",
       " 0.010365731082856655,\n",
       " -0.045766379684209824,\n",
       " 0.047701653093099594,\n",
       " -0.02462482638657093,\n",
       " -0.03456123545765877,\n",
       " 0.03323351964354515,\n",
       " 0.0369257889688015,\n",
       " -0.015868011862039566,\n",
       " -0.020677432417869568,\n",
       " -0.0798477828502655,\n",
       " -0.031529709696769714,\n",
       " -0.016192004084587097,\n",
       " -0.0015117052244022489,\n",
       " 0.01224633026868105,\n",
       " 0.07830173522233963,\n",
       " 0.03344554454088211,\n",
       " 0.007660152856260538,\n",
       " 0.000679933640640229,\n",
       " 0.0031864691991358995,\n",
       " -0.03479974716901779,\n",
       " -0.014999081380665302,\n",
       " 0.03731534630060196,\n",
       " -0.009754819795489311,\n",
       " -0.04331761598587036,\n",
       " 0.07718624174594879,\n",
       " -0.035620544105768204,\n",
       " 0.007289487402886152,\n",
       " 0.01374379638582468,\n",
       " 0.04909307137131691,\n",
       " -0.00847141444683075,\n",
       " -0.015173135325312614,\n",
       " 0.013521650806069374,\n",
       " -0.018822452053427696,\n",
       " 0.02364182658493519,\n",
       " 0.02017911709845066,\n",
       " 0.001439171377569437,\n",
       " -0.013098672963678837,\n",
       " 0.01767466403543949,\n",
       " 0.023364931344985962,\n",
       " -0.02348613552749157,\n",
       " -0.00924301240593195,\n",
       " 0.09694280475378036,\n",
       " -0.04579820856451988,\n",
       " -0.04389147087931633,\n",
       " -0.0030017364770174026,\n",
       " -0.0032807542011141777,\n",
       " -0.0685979574918747,\n",
       " 0.004693944007158279,\n",
       " 0.005970361176878214,\n",
       " -0.22755229473114014,\n",
       " -0.0005921216798014939,\n",
       " 0.06682659685611725,\n",
       " 0.06356530636548996,\n",
       " -0.06255921721458435,\n",
       " 0.03184808790683746,\n",
       " 0.019693760201334953,\n",
       " -0.0397847555577755,\n",
       " -0.07047154009342194,\n",
       " 0.04987606033682823,\n",
       " 0.05700564384460449,\n",
       " 0.010697223246097565,\n",
       " 0.012983124703168869,\n",
       " -0.029270948842167854,\n",
       " 0.0047513688914477825,\n",
       " 0.08082938194274902,\n",
       " 0.08776602149009705,\n",
       " -0.04735748469829559,\n",
       " 0.03231258690357208,\n",
       " -0.04937891289591789,\n",
       " 0.0006466894992627203,\n",
       " -0.014591830782592297,\n",
       " 0.1845884919166565,\n",
       " -0.053302276879549026,\n",
       " -0.0002218032896053046,\n",
       " -0.004666523076593876,\n",
       " 0.03609587252140045,\n",
       " 0.048575397580862045,\n",
       " 0.06161108985543251,\n",
       " -0.022564448416233063,\n",
       " 0.055886588990688324,\n",
       " -0.026477621868252754,\n",
       " 0.06451528519392014,\n",
       " -0.024585643783211708,\n",
       " 0.006214447319507599,\n",
       " 0.027085278183221817,\n",
       " 0.009757655672729015,\n",
       " -0.024927780032157898,\n",
       " 0.023976119235157967,\n",
       " -0.032775670289993286,\n",
       " 0.045717015862464905,\n",
       " -0.004094367381185293,\n",
       " -0.04116463661193848,\n",
       " 0.010081402026116848,\n",
       " 0.07221299409866333,\n",
       " 0.05550742149353027,\n",
       " 0.02535165101289749,\n",
       " -0.07161759585142136,\n",
       " -0.056813132017850876,\n",
       " -0.009707162156701088,\n",
       " -0.030689941719174385,\n",
       " -0.010066110640764236,\n",
       " 0.019482983276247978,\n",
       " 0.0016789523651823401,\n",
       " 0.06847911328077316,\n",
       " 0.014994543977081776,\n",
       " 0.0007662490243092179,\n",
       " -0.022777069360017776,\n",
       " 0.0268991868942976,\n",
       " -0.014439505524933338,\n",
       " -0.018720107153058052,\n",
       " 0.01159164123237133,\n",
       " 0.11504840850830078,\n",
       " 0.0646745041012764,\n",
       " 0.04032905027270317]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Testing\"\n",
    "query_result = huggingface_embeddings.embed_query(text)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd457c9-1135-4a0a-adde-629098d96f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "{'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 0, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}\n",
      "\n",
      " Similarity Score: 0.8130470113506805\n",
      "\n",
      "Evaluating AI for Law: Bridging the Gap with\n",
      "Open-Source Solutions\n",
      "Rohan Bhambhoria1,2[0000−0002−2597−670X],\n",
      "Samuel Dahan1,2,3[0000−0002−1079−8998],\n",
      "Jonathan Li2[0000−0002−7095−805X], and\n",
      "Xiaodan Zhu1,2[0000−0003−3856−3696]\n",
      "1 Queen’s University, Kingston ON K7L3N6, Canada\n",
      "{r.bhambhoria, samuel.dahan, jxl, xiaodan.zhu}@queensu.ca\n",
      "2 Ingenuity Labs\n",
      "3 Cornell University\n",
      "Abstract. This study evaluates the performance of general-purpose AI,\n",
      "like ChatGPT, in legal question-answering tasks, highlighting significant\n",
      "risks to legal professionals and clients. It suggests leveraging founda-\n",
      "tional models enhanced by domain-specific knowledge to overcome these\n",
      "issues. The paper advocates for creating open-source legal AI systems\n",
      "to improve accuracy, transparency, and narrative diversity, addressing\n",
      "general AI’s shortcomings in legal contexts.\n",
      "Keywords: Law · Open-Source · Large Language Models.\n",
      "1\n",
      "Introduction\n",
      "In recent times, the rise of Large Language Models (LLMs) has become promi-\n",
      "nent, especially with the unprecedented growth of ChatGPT, marking it as the\n",
      "fastest-expanding consumer application to date. LLMs have shown extensive\n",
      "utility in tasks related to productivity and in systems designed for low-stakes\n",
      "decision-making, such as composing emails. However, its application in high-\n",
      "stakes decision-making areas, including contract drafting or medical diagnostics,\n",
      "is met with cautious adaptation due to concerns about its large-scale deploy-\n",
      "*************************\n",
      "{'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 4, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}\n",
      "\n",
      " Similarity Score: 0.806621829662316\n",
      "\n",
      "in legal practice but also advocates for a targeted approach towards develop-\n",
      "ing domain-specific, open-source legal AI solutions to address these challenges\n",
      "effectively.\n",
      "Our preliminary study aims to advance the literature on AI benchmarking\n",
      "focusing on evaluating GPT-4’s assistance in practical lawyering [18] tasks - espe-\n",
      "cially Question-Answer, aiming to advance the understanding of AI’s qualitative\n",
      "impacts in law.\n",
      "*************************\n",
      "{'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 4, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}\n",
      "\n",
      " Similarity Score: 0.7874390076639464\n",
      "\n",
      "by focusing on applying AI to practical, real-world legal tasks through a domain-\n",
      "specific, open-source platform. We aim to directly evaluate AI’s effectiveness in\n",
      "performing tasks that mirror the day-to-day work of legal professionals, moving\n",
      "beyond theoretical benchmarks to assess practical utility and integration into\n",
      "legal workflows.\n",
      "Contrastingly, recent work investigates AI’s capabilities in contract review,\n",
      "a narrowly defined task where AI has been shown to excel, even outperforming\n",
      "lawyers in previous studies [20,21]. This focus contrasts with our project, which\n",
      "extends beyond document analysis to cover a broader range of practical legal\n",
      "tasks through a domain-specific, open-source platform, aiming to assess AI’s\n",
      "utility in a wider legal context.\n",
      "Finally, recent work by Choi et al, presents meaningful insights into how AI\n",
      "may augment the performance of some lawyers, particularly the lower-performing\n",
      "ones. However, it also primarily focuses on tasks that are relatively easier for\n",
      "LLMs, such as drafting legal documents and answering hypothetical questions\n",
      "with provided materials. Our project aims to bridge these gaps by providing a\n",
      "more detailed and nuanced examination of AI’s capabilities and deficiencies in\n",
      "a broader range of legal tasks, moving beyond the realms explored by the afore-\n",
      "mentioned studies. This endeavor not only highlights AI’s current limitations\n",
      "in legal practice but also advocates for a targeted approach towards develop-\n"
     ]
    }
   ],
   "source": [
    "# Create a FAISS Vector Store from the documents and the embeddings from embedding model\n",
    "db = FAISS.from_documents(docs, huggingface_embeddings)\n",
    "\n",
    "# Test the retrieval of similar documents with a sample question along with the similarity scores\n",
    "question = \"What is the conclusion of the paper 'Evaluating AI for Law: Bridging the Gap with Open-Source Solutions' ?\"\n",
    "searchDocs = db.similarity_search_with_relevance_scores(question)\n",
    "\n",
    "for doc in searchDocs[:3]:\n",
    "    print(\"*\"*25)\n",
    "    print(doc[0].metadata)\n",
    "    print(\"\\n Similarity Score: \"+ str(doc[1]))\n",
    "    print(\"\\n\"+doc[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6958c27-50ad-493a-80b4-011ea44f1d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Evaluating AI for Law: Bridging the Gap with\\nOpen-Source Solutions\\nRohan Bhambhoria1,2[0000−0002−2597−670X],\\nSamuel Dahan1,2,3[0000−0002−1079−8998],\\nJonathan Li2[0000−0002−7095−805X], and\\nXiaodan Zhu1,2[0000−0003−3856−3696]\\n1 Queen’s University, Kingston ON K7L3N6, Canada\\n{r.bhambhoria, samuel.dahan, jxl, xiaodan.zhu}@queensu.ca\\n2 Ingenuity Labs\\n3 Cornell University\\nAbstract. This study evaluates the performance of general-purpose AI,\\nlike ChatGPT, in legal question-answering tasks, highlighting significant\\nrisks to legal professionals and clients. It suggests leveraging founda-\\ntional models enhanced by domain-specific knowledge to overcome these\\nissues. The paper advocates for creating open-source legal AI systems\\nto improve accuracy, transparency, and narrative diversity, addressing\\ngeneral AI’s shortcomings in legal contexts.\\nKeywords: Law · Open-Source · Large Language Models.\\n1\\nIntroduction\\nIn recent times, the rise of Large Language Models (LLMs) has become promi-\\nnent, especially with the unprecedented growth of ChatGPT, marking it as the\\nfastest-expanding consumer application to date. LLMs have shown extensive\\nutility in tasks related to productivity and in systems designed for low-stakes\\ndecision-making, such as composing emails. However, its application in high-\\nstakes decision-making areas, including contract drafting or medical diagnostics,\\nis met with cautious adaptation due to concerns about its large-scale deploy-', metadata={'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 0, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}),\n",
       " Document(page_content='in legal practice but also advocates for a targeted approach towards develop-\\ning domain-specific, open-source legal AI solutions to address these challenges\\neffectively.\\nOur preliminary study aims to advance the literature on AI benchmarking\\nfocusing on evaluating GPT-4’s assistance in practical lawyering [18] tasks - espe-\\ncially Question-Answer, aiming to advance the understanding of AI’s qualitative\\nimpacts in law.', metadata={'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 4, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}),\n",
       " Document(page_content='by focusing on applying AI to practical, real-world legal tasks through a domain-\\nspecific, open-source platform. We aim to directly evaluate AI’s effectiveness in\\nperforming tasks that mirror the day-to-day work of legal professionals, moving\\nbeyond theoretical benchmarks to assess practical utility and integration into\\nlegal workflows.\\nContrastingly, recent work investigates AI’s capabilities in contract review,\\na narrowly defined task where AI has been shown to excel, even outperforming\\nlawyers in previous studies [20,21]. This focus contrasts with our project, which\\nextends beyond document analysis to cover a broader range of practical legal\\ntasks through a domain-specific, open-source platform, aiming to assess AI’s\\nutility in a wider legal context.\\nFinally, recent work by Choi et al, presents meaningful insights into how AI\\nmay augment the performance of some lawyers, particularly the lower-performing\\nones. However, it also primarily focuses on tasks that are relatively easier for\\nLLMs, such as drafting legal documents and answering hypothetical questions\\nwith provided materials. Our project aims to bridge these gaps by providing a\\nmore detailed and nuanced examination of AI’s capabilities and deficiencies in\\na broader range of legal tasks, moving beyond the realms explored by the afore-\\nmentioned studies. This endeavor not only highlights AI’s current limitations\\nin legal practice but also advocates for a targeted approach towards develop-', metadata={'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 4, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}),\n",
       " Document(page_content='posed open-access, yet expert-restricted, legal AI model represents a paradigm\\nshift in the development of legal technology. It not only promises enhanced per-\\nformance in terms of accuracy and relevance but also embodies a progressive\\napproach towards democratizing legal knowledge and fostering an inclusive legal\\ntech ecosystem.\\n7\\nConclusion\\nArtificial intelligence has been bringing a profound impact on legal applications.\\nIn this work, we bring a call for open-source legal language models. This is done\\nas a means to address limitations of general-purpose language models which may\\nhave underlying limitations, affecting their usage for high-stakes decision making.\\nWe provide a recipe for creating a legal language model, called OpenJustice. We\\nfurther introduce a real-world high-quality dataset manually annotated by legal\\nexperts, called LegalQA, and run experiments outlining performance of current\\nstate-of-the-art LLMs. We place further emphasis on highlighting the limitations\\nin the automatic evaluation process when used on legal datasets.\\n8\\nAcknowledgements\\nWe would like to thank students of the Conflict Analytics Lab at Queen’s Uni-\\nversity Faculty of Law for being a part of initial efforts put into this initiative,\\nand David Liang for coordinating efforts.', metadata={'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 13, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever() \n",
    "docs = retriever.get_relevant_documents(question)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ab217-f210-49a3-9d0b-b83b8de40b40",
   "metadata": {},
   "source": [
    "#### Provide API token to access replicate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7ff1b5f-9378-4a46-bc88-c6b4b199e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\"keys.env\") \n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = config['replicate_api_token'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f03b83de-6d59-4c68-bc29-6ec57b77398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate runs machine learning models in the cloud\n",
    "\n",
    "llm = Replicate(\n",
    "                model=\"meta/meta-llama-3-70b-instruct\", \n",
    "                model_kwargs={\"temperature\": 0.1, \"max_length\": 500, \"top_p\": 1},\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce7b92-59fd-4634-963e-0e966d5274c1",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726ba73-6a17-4691-9be6-1dcc540cb9f4",
   "metadata": {},
   "source": [
    "### Enough Code!  Let's chitchat!\n",
    "#### ------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98ad7c6c-7020-4091-9e2e-af9b1e2e5140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help! However, I need more information to provide an accurate answer. After conducting a search, I couldn't find a specific paper titled \"Evaluating AI for Law: Bridging the Gap with Open-Source Solutions\" by Rohan Bhambhoria.\n",
      "\n",
      "Could you please provide more context or details about the paper, such as:\n",
      "\n",
      "1. The publication or journal it was published in?\n",
      "2. The year or approximate timeframe you're looking for?\n",
      "3. Any other relevant information that might help me narrow down the search?\n",
      "\n",
      "I'll do my best to assist you in finding the answer!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(llm.invoke(\"When was the paper titled 'Evaluating AI for Law: Bridging the Gap with Open-Source Solutions', with the author Rohan Bhambhoria, published?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80c75ade-8a70-48a2-aa35-a421baa29731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you with that!\n",
      "\n",
      "The paper \"Evaluating AI for Law: Bridging the Gap with Open-Source Solutions\" explores the potential of artificial intelligence (AI) in the legal domain and proposes open-source solutions to address the challenges of evaluating AI systems for legal applications.\n",
      "\n",
      "After reviewing the paper, I found that the conclusion highlights the following key points:\n",
      "\n",
      "1. **Need for standardized evaluation frameworks**: The authors emphasize the importance of developing standardized evaluation frameworks for AI systems in law, which can ensure consistency, transparency, and reproducibility across different use cases.\n",
      "2. **Open-source solutions as a bridge**: The paper concludes that open-source solutions can bridge the gap between AI research and practical legal applications by providing accessible, customizable, and community-driven tools for evaluating AI systems.\n",
      "3. **Collaboration between academia, industry, and legal practitioners**: The authors stress the need for interdisciplinary collaboration to develop effective evaluation methods and ensure that AI systems meet the needs of legal professionals and stakeholders.\n",
      "4. **Future research directions**: The conclusion outlines potential future research directions, including the development of more sophisticated evaluation metrics, exploring explainability and transparency techniques, and investigating the ethical implications of AI adoption in law.\n",
      "\n",
      "Overall, the paper's conclusion emphasizes the importance of a collaborative effort to establish a robust evaluation framework for AI in law, leveraging open-source solutions to facilitate this process.\n",
      "\n",
      "Would you like me to provide more information or context about this paper?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(llm.invoke(\"What is the conclusion of the paper 'Evaluating AI for Law: Bridging the Gap with Open-Source Solutions' ?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb678c4-7337-4e4d-9d84-3d184c531c65",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d247a-3ec2-4cf3-9176-e73c24e0d85e",
   "metadata": {},
   "source": [
    "#### Time to employ RAG system! \n",
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df79fcdc-d7c3-47ac-9eb5-b7ecd28b924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instructions to the LLM\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "1. If you don't know the answer, don't try to make up an answer. Just say \"Sorry I can't find the final answer!\".\n",
    "2. If you find the answer, write the answer in a concise way with five sentences maximum.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Vector db as a retriever with similarity search and uses 4 source documents\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4}) \n",
    "\n",
    "# Define the prompt template with variables\n",
    "PROMPT = PromptTemplate(\n",
    "\ttemplate=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create the retrievalQA by setting LLM, retriever and other parameters\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "\tllm=llm,\n",
    "\tchain_type=\"stuff\",\n",
    "\tretriever=retriever,\n",
    "\treturn_source_documents=True,\n",
    "\tchain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "def print_readable(result):\n",
    "    print(\"\\n\"+\"-\"*100)\n",
    "    print(result)\n",
    "    print(\"\\n\"+\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aea7c7-5850-4067-a35a-c2a95d18115e",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a0c44-5c95-4007-89c8-53d0f0fe969c",
   "metadata": {},
   "source": [
    "#### Shall we test our RAG System? \n",
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcb68b12-a596-4a04-ae18-01603691cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sorry I can't find the final answer! The provided context does not mention the publication date of the paper.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = retrievalQA.invoke({\"query\": \"When was the paper titled 'Evaluating AI for Law: Bridging the Gap with Open-Source Solutions', with the author Rohan Bhambhoria, published?\"})\n",
    "print_readable(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ba9e3fe-3b0e-4c43-9bda-f70172a5925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The conclusion of the paper is that artificial intelligence has a profound impact on legal applications, and the authors advocate for open-source legal language models to address the limitations of general-purpose language models in high-stakes decision making. They propose creating a legal language model called OpenJustice and introduce a real-world dataset called LegalQA to evaluate the performance of current state-of-the-art LLMs.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = retrievalQA.invoke({\"query\": \"What is the conclusion of the paper 'Evaluating AI for Law: Bridging the Gap with Open-Source Solutions' ?\"})\n",
    "print_readable(result['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61611391-d447-45b1-9349-321ad4959abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 documents retrieved which are relevant to the query.\n",
      "****************************************************************************************************\n",
      "Relevant Document #1:\n",
      "Source file: Dataset/Evaluating AI for Law.pdf, Page: 0\n",
      "Content: Evaluating AI for Law: Bridging the Gap with\n",
      "Open-Source Solutions\n",
      "Rohan Bhambhoria1,2[0000−0002−2597−670X],\n",
      "Samuel Dahan1,2,3[0000−0002−1079−8998],\n",
      "Jonathan Li2[0000−0002−7095−805X], and\n",
      "Xiaodan Zhu1,2[0000−0003−3856−3696]\n",
      "1 Queen’s University, Kingston ON K7L3N6, Canada\n",
      "{r.bhambhoria, samuel.dahan, jxl, xiaodan.zhu}@queensu.ca\n",
      "2 Ingenuity Labs\n",
      "3 Cornell University\n",
      "Abstract. This study evaluates the performance of general-purpose AI,\n",
      "like ChatGPT, in legal question-answering tasks, highlighting significant\n",
      "risks to legal professionals and clients. It suggests leveraging founda-\n",
      "tional models enhanced by domain-specific knowledge to overcome these\n",
      "issues. The paper advocates for creating open-source legal AI systems\n",
      "to improve accuracy, transparency, and narrative diversity, addressing\n",
      "general AI’s shortcomings in legal contexts.\n",
      "Keywords: Law · Open-Source · Large Language Models.\n",
      "1\n",
      "Introduction\n",
      "In recent times, the rise of Large Language Models (LLMs) has become promi-\n",
      "nent, especially with the unprecedented growth of ChatGPT, marking it as the\n",
      "fastest-expanding consumer application to date. LLMs have shown extensive\n",
      "utility in tasks related to productivity and in systems designed for low-stakes\n",
      "decision-making, such as composing emails. However, its application in high-\n",
      "stakes decision-making areas, including contract drafting or medical diagnostics,\n",
      "is met with cautious adaptation due to concerns about its large-scale deploy-\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #2:\n",
      "Source file: Dataset/Evaluating AI for Law.pdf, Page: 4\n",
      "Content: in legal practice but also advocates for a targeted approach towards develop-\n",
      "ing domain-specific, open-source legal AI solutions to address these challenges\n",
      "effectively.\n",
      "Our preliminary study aims to advance the literature on AI benchmarking\n",
      "focusing on evaluating GPT-4’s assistance in practical lawyering [18] tasks - espe-\n",
      "cially Question-Answer, aiming to advance the understanding of AI’s qualitative\n",
      "impacts in law.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #3:\n",
      "Source file: Dataset/Evaluating AI for Law.pdf, Page: 4\n",
      "Content: by focusing on applying AI to practical, real-world legal tasks through a domain-\n",
      "specific, open-source platform. We aim to directly evaluate AI’s effectiveness in\n",
      "performing tasks that mirror the day-to-day work of legal professionals, moving\n",
      "beyond theoretical benchmarks to assess practical utility and integration into\n",
      "legal workflows.\n",
      "Contrastingly, recent work investigates AI’s capabilities in contract review,\n",
      "a narrowly defined task where AI has been shown to excel, even outperforming\n",
      "lawyers in previous studies [20,21]. This focus contrasts with our project, which\n",
      "extends beyond document analysis to cover a broader range of practical legal\n",
      "tasks through a domain-specific, open-source platform, aiming to assess AI’s\n",
      "utility in a wider legal context.\n",
      "Finally, recent work by Choi et al, presents meaningful insights into how AI\n",
      "may augment the performance of some lawyers, particularly the lower-performing\n",
      "ones. However, it also primarily focuses on tasks that are relatively easier for\n",
      "LLMs, such as drafting legal documents and answering hypothetical questions\n",
      "with provided materials. Our project aims to bridge these gaps by providing a\n",
      "more detailed and nuanced examination of AI’s capabilities and deficiencies in\n",
      "a broader range of legal tasks, moving beyond the realms explored by the afore-\n",
      "mentioned studies. This endeavor not only highlights AI’s current limitations\n",
      "in legal practice but also advocates for a targeted approach towards develop-\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Relevant Document #4:\n",
      "Source file: Dataset/Evaluating AI for Law.pdf, Page: 13\n",
      "Content: posed open-access, yet expert-restricted, legal AI model represents a paradigm\n",
      "shift in the development of legal technology. It not only promises enhanced per-\n",
      "formance in terms of accuracy and relevance but also embodies a progressive\n",
      "approach towards democratizing legal knowledge and fostering an inclusive legal\n",
      "tech ecosystem.\n",
      "7\n",
      "Conclusion\n",
      "Artificial intelligence has been bringing a profound impact on legal applications.\n",
      "In this work, we bring a call for open-source legal language models. This is done\n",
      "as a means to address limitations of general-purpose language models which may\n",
      "have underlying limitations, affecting their usage for high-stakes decision making.\n",
      "We provide a recipe for creating a legal language model, called OpenJustice. We\n",
      "further introduce a real-world high-quality dataset manually annotated by legal\n",
      "experts, called LegalQA, and run experiments outlining performance of current\n",
      "state-of-the-art LLMs. We place further emphasis on highlighting the limitations\n",
      "in the automatic evaluation process when used on legal datasets.\n",
      "8\n",
      "Acknowledgements\n",
      "We would like to thank students of the Conflict Analytics Lab at Queen’s Uni-\n",
      "versity Faculty of Law for being a part of initial efforts put into this initiative,\n",
      "and David Liang for coordinating efforts.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "relevant_docs = result['source_documents']\n",
    "print(f'There are {len(relevant_docs)} documents retrieved which are relevant to the query.')\n",
    "print(\"*\" * 100)\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "\tprint(\n",
    "\t\tf\"Relevant Document #{i + 1}:\\nSource file: {doc.metadata['source']}, Page: {doc.metadata['page']}\\nContent: {doc.page_content}\")\n",
    "\tprint(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a437cef-3374-4972-b9e7-520a8a660e8e",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22092220-7166-41b9-aabd-d2ead0c7eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After conducting a search, I found that the paper \"Evaluating AI for Law: Bridging the Gap with Open-Source Solutions\" uses several datasets to evaluate AI models for legal applications. The specific datasets used in the paper are:\n",
      "\n",
      "1. **CaseLaw**: A dataset of 7,700 court cases from the United States, annotated with relevant information such as case type, jurisdiction, and outcome.\n",
      "2. **European Court of Human Rights (ECHR)**: A dataset of 11,000 court cases from the European Court of Human Rights, annotated with information such as article violations and outcome.\n",
      "3. **Stanford Large Dataset (SLDT)**: A dataset of 150,000 court cases from the United States, annotated with information such as case type, jurisdiction, and outcome.\n",
      "4. **Legal Information Institute (LII)**: A dataset of 100,000 court cases from the United States, annotated with information such as case type, jurisdiction, and outcome.\n",
      "\n",
      "These datasets are used to evaluate various AI models for tasks such as case classification, outcome prediction, and legal text analysis. The authors also provide an open-source framework for evaluating AI models on these datasets, which can be found on GitHub.\n",
      "\n",
      "Please note that the availability and accessibility of these datasets might be subject to certain restrictions or requirements. If you're interested in using these datasets for your own research or projects, I recommend checking the original paper or contacting the authors for more information.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(llm.invoke(\"what is the dataset used in the paper titled Evaluating AI for Law: Bridging the Gap with Open-Source Solutions?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef936776-253a-4922-9617-40e7bdd0ac18",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f58dc30-0bdd-4086-8d75-819e006ffcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The dataset used in the paper is called LegalQA, which is a high-quality dataset manually annotated by legal experts.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = retrievalQA.invoke({\"query\": \"what is the dataset used in the paper titled Evaluating AI for Law: Bridging the Gap with Open-Source Solutions?\"})\n",
    "print_readable(res['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc58330-76c1-463f-975b-16cda5a47cdd",
   "metadata": {},
   "source": [
    "</br></br></br></br></br></br></br></br></br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcbee9-48d1-4de1-9aab-7399ed7ce851",
   "metadata": {},
   "source": [
    "### What about continuous chatting?\n",
    "#### --------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b68fa2d8-af60-4cb6-bcc7-45d28bb500ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import (ConversationalRetrievalChain)\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question in your own words as truthfully as possible from the context given to you.\n",
    "If you do not know the answer to the question, simply respond with \"I don't know. Can you ask another question\".\n",
    "If questions are asked where there is no relevant context available, simply respond with \"I don't know. Please ask a question relevant to the documents\"\n",
    "Context: {context}\n",
    "\n",
    "\n",
    "{chat_history}\n",
    "Human: {question}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"chat_history\", \"question\"], template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer')\n",
    "\n",
    "# Create the custom chain\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "                    llm=llm, retriever=retriever, memory=memory,\n",
    "                    # get_chat_history=get_chat_history, \n",
    "                    return_source_documents=True,\n",
    "                    combine_docs_chain_kwargs={'prompt': prompt}\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "15feba56-d56a-49dd-b78a-7fa423c2d1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The dataset used in the paper is called LegalQA, which is a high-quality dataset manually annotated by legal experts.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = chain(\"what is the dataset used in the paper titled Evaluating AI for Law: Bridging the Gap with Open-Source Solutions?\")\n",
    "print_readable(res['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eadd7ed0-a1eb-4587-a8de-e83b4fa88e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The LegalQA dataset is a high-quality dataset of over 2000 questions asked by laypeople on real legal questions and answers vetted by legal experts. The questions are sourced from an online legal community, and law students were asked to write expert answers to these questions. The dataset is designed to reflect real-world scenarios and address various dimensions desirable for a language model in aiding laypeople with legal tasks.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = chain(\"Can you provide more details about this dataset?\")\n",
    "print_readable(res['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "06428863-eb9b-4891-adaf-60f842c69cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The conclusion of the paper is that artificial intelligence has a profound impact on legal applications, and the authors call for open-source legal language models to address the limitations of general-purpose language models in high-stakes decision-making. They propose creating a legal language model, called OpenJustice, and introduce the LegalQA dataset, highlighting the limitations of automatic evaluation processes when used on legal datasets.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = chain(\"What is the conclusion of this paper?\")\n",
    "print_readable(res['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7cd8a890-29d7-4d37-98b2-6e17cef68ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "{'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 0, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}\n",
      "Evaluating AI for Law: Bridging the Gap with\n",
      "Open-Source Solutions\n",
      "Rohan Bhambhoria1,2[0000−0002−2597−670X],\n",
      "Samuel Dahan1,2,3[0000−0002−1079−8998],\n",
      "Jonathan Li2[0000−0002−7095−805X], and\n",
      "Xiaodan Zhu1,2[0000−0003−3856−3696]\n",
      "1 Queen’s University, Kingston ON K7L3N6, Canada\n",
      "{r.bhambhoria, samuel.dahan, jxl, xiaodan.zhu}@queensu.ca\n",
      "2 Ingenuity Labs\n",
      "3 Cornell University\n",
      "Abstract. This study evaluates the performance of general-purpose AI,\n",
      "like ChatGPT, in legal question-answering tasks, highlighting significant\n",
      "risks to legal professionals and clients. It suggests leveraging founda-\n",
      "tional models enhanced by domain-specific knowledge to overcome these\n",
      "issues. The paper advocates for creating open-source legal AI systems\n",
      "to improve accuracy, transparency, and narrative diversity, addressing\n",
      "general AI’s shortcomings in legal contexts.\n",
      "Keywords: Law · Open-Source · Large Language Models.\n",
      "1\n",
      "Introduction\n",
      "In recent times, the rise of Large Language Models (LLMs) has become promi-\n",
      "nent, especially with the unprecedented growth of ChatGPT, marking it as the\n",
      "fastest-expanding consumer application to date. LLMs have shown extensive\n",
      "utility in tasks related to productivity and in systems designed for low-stakes\n",
      "decision-making, such as composing emails. However, its application in high-\n",
      "stakes decision-making areas, including contract drafting or medical diagnostics,\n",
      "is met with cautious adaptation due to concerns about its large-scale deploy-\n",
      "**************************************************\n",
      "{'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 4, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}\n",
      "in legal practice but also advocates for a targeted approach towards develop-\n",
      "ing domain-specific, open-source legal AI solutions to address these challenges\n",
      "effectively.\n",
      "Our preliminary study aims to advance the literature on AI benchmarking\n",
      "focusing on evaluating GPT-4’s assistance in practical lawyering [18] tasks - espe-\n",
      "cially Question-Answer, aiming to advance the understanding of AI’s qualitative\n",
      "impacts in law.\n",
      "**************************************************\n",
      "{'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 4, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}\n",
      "by focusing on applying AI to practical, real-world legal tasks through a domain-\n",
      "specific, open-source platform. We aim to directly evaluate AI’s effectiveness in\n",
      "performing tasks that mirror the day-to-day work of legal professionals, moving\n",
      "beyond theoretical benchmarks to assess practical utility and integration into\n",
      "legal workflows.\n",
      "Contrastingly, recent work investigates AI’s capabilities in contract review,\n",
      "a narrowly defined task where AI has been shown to excel, even outperforming\n",
      "lawyers in previous studies [20,21]. This focus contrasts with our project, which\n",
      "extends beyond document analysis to cover a broader range of practical legal\n",
      "tasks through a domain-specific, open-source platform, aiming to assess AI’s\n",
      "utility in a wider legal context.\n",
      "Finally, recent work by Choi et al, presents meaningful insights into how AI\n",
      "may augment the performance of some lawyers, particularly the lower-performing\n",
      "ones. However, it also primarily focuses on tasks that are relatively easier for\n",
      "LLMs, such as drafting legal documents and answering hypothetical questions\n",
      "with provided materials. Our project aims to bridge these gaps by providing a\n",
      "more detailed and nuanced examination of AI’s capabilities and deficiencies in\n",
      "a broader range of legal tasks, moving beyond the realms explored by the afore-\n",
      "mentioned studies. This endeavor not only highlights AI’s current limitations\n",
      "in legal practice but also advocates for a targeted approach towards develop-\n",
      "**************************************************\n",
      "{'source': 'Dataset/Evaluating AI for Law.pdf', 'file_path': 'Dataset/Evaluating AI for Law.pdf', 'page': 13, 'total_pages': 16, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240419005128Z', 'modDate': 'D:20240419005128Z', 'trapped': ''}\n",
      "posed open-access, yet expert-restricted, legal AI model represents a paradigm\n",
      "shift in the development of legal technology. It not only promises enhanced per-\n",
      "formance in terms of accuracy and relevance but also embodies a progressive\n",
      "approach towards democratizing legal knowledge and fostering an inclusive legal\n",
      "tech ecosystem.\n",
      "7\n",
      "Conclusion\n",
      "Artificial intelligence has been bringing a profound impact on legal applications.\n",
      "In this work, we bring a call for open-source legal language models. This is done\n",
      "as a means to address limitations of general-purpose language models which may\n",
      "have underlying limitations, affecting their usage for high-stakes decision making.\n",
      "We provide a recipe for creating a legal language model, called OpenJustice. We\n",
      "further introduce a real-world high-quality dataset manually annotated by legal\n",
      "experts, called LegalQA, and run experiments outlining performance of current\n",
      "state-of-the-art LLMs. We place further emphasis on highlighting the limitations\n",
      "in the automatic evaluation process when used on legal datasets.\n",
      "8\n",
      "Acknowledgements\n",
      "We would like to thank students of the Conflict Analytics Lab at Queen’s Uni-\n",
      "versity Faculty of Law for being a part of initial efforts put into this initiative,\n",
      "and David Liang for coordinating efforts.\n"
     ]
    }
   ],
   "source": [
    "for d in res['source_documents']:\n",
    "    print(\"*\"*50)\n",
    "    print(d.metadata)\n",
    "    print(d.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d7a735a5-35a9-4995-97c6-dcbd7a36eebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The paper \"From Language Models to Practical Self-Improving Computer Agents\" proposes a methodology to create AI computer agents that can carry out diverse computer tasks and self-improve by developing tools and augmentations to enable themselves to solve increasingly complex tasks. The authors suggest that instead of manually developing static software to augment large language models (LLMs) through human engineering effort, an LLM agent can systematically generate software to augment itself. They demonstrate this approach through case studies, showing that an LLM agent can generate and use various augmentations, such as retrieval, internet search, web navigation, and text editor capabilities, to solve real-world computer tasks.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = chain(\"Do you know about the paper titled 'From Language Models to Practical Self-Improving Computer Agents'?\")\n",
    "print_readable(res['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f81bd18a-8a96-4a3c-bee3-378f7dcb9e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The paper concludes that the proposed methodology enables an LLM agent to complete diverse tasks within a real-world computer system, and that the approach is both flexible due to its free-form augmentation capabilities and simple in algorithmic design. The authors also highlight the importance of effective prompt engineering in achieving intended outcomes. Additionally, they acknowledge the limitations of their existing implementation and invite future works to address these limitations, expecting that the effectiveness of their methodology will increase as more capable LLMs become available.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = chain(\"What is the conclusion of this paper?\")\n",
    "print_readable(res['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d6967f3-1423-4767-a5f7-df60be285324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "{'source': 'Dataset/Practical Self-Improving Computer Agents.pdf', 'file_path': 'Dataset/Practical Self-Improving Computer Agents.pdf', 'page': 0, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'GPL Ghostscript 10.01.2', 'creationDate': \"D:20240418202537-04'00'\", 'modDate': \"D:20240418202537-04'00'\", 'trapped': ''}\n",
      "arXiv:2404.11964v1  [cs.AI]  18 Apr 2024\n",
      "From Language Models to Practical Self-Improving\n",
      "Computer Agents\n",
      "Alex Sheng\n",
      "New York University\n",
      "alexsheng4@gmail.com\n",
      "Abstract\n",
      "We develop a simple and straightforward methodology to create AI computer\n",
      "agents that can carry out diverse computer tasks and self-improve by develop-\n",
      "ing tools and augmentations to enable themselves to solve increasingly complex\n",
      "tasks. As large language models (LLMs) have been shown to beneﬁt from non-\n",
      "parametric augmentations, a signiﬁcant body of recent work has focused on de-\n",
      "veloping software that augments LLMs with various capabilities. Rather than\n",
      "manually developing static software to augment LLMs through human engineer-\n",
      "ing effort, we propose that an LLM agent can systematically generate software\n",
      "to augment itself. We show, through a few case studies, that a minimal querying\n",
      "loop with appropriate prompt engineering allows an LLM to generate and use var-\n",
      "ious augmentations, freely extending its own capabilities to carry out real-world\n",
      "computer tasks. Starting with only terminal access, we prompt an LLM agent to\n",
      "augment itself with retrieval, internet search, web navigation, and text editor capa-\n",
      "bilities. The agent effectively uses these various tools to solve problems including\n",
      "automated software development and web-based tasks.\n",
      "1\n",
      "Introduction\n",
      "Large Language Models (LLMs) pretrained on internet-scale data have been shown to develop some\n",
      "**************************************************\n",
      "{'source': 'Dataset/Practical Self-Improving Computer Agents.pdf', 'file_path': 'Dataset/Practical Self-Improving Computer Agents.pdf', 'page': 20, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'GPL Ghostscript 10.01.2', 'creationDate': \"D:20240418202537-04'00'\", 'modDate': \"D:20240418202537-04'00'\", 'trapped': ''}\n",
      "understanding\n",
      "of\n",
      "Graham ’s insights\n",
      "on\n",
      "this\n",
      "topic , visit [How to Think for\n",
      "Yourself ](\n",
      "https:// paulgraham .com/think.html ).\n",
      "4\n",
      "Analysis\n",
      "Our experiments show that our self-improving agent methodology enables an LLM agent to com-\n",
      "plete diverse tasks within a real-world computer system. Our approach is both ﬂexible because of\n",
      "its free-form augmentation capabilities and simple in algorithmic design. We also ﬁnd that effective\n",
      "prompt engineering has an important impact on an agent’s ability to successfully achieve intended\n",
      "outcomes.\n",
      "4.1\n",
      "Limitations\n",
      "Our existing implementation is rudimentary, and possesses various limitations that we enthusiasti-\n",
      "cally invite future works to address.\n",
      "Limitations of underlying models. Our methodology relies on the reasoning and code generation\n",
      "capabilities of underlying models. We expect that a self-improving agent implemented without a\n",
      "sufﬁciently capable underlying model would be less successful in developing and applying software\n",
      "to augment itself. Furthermore, modiﬁcations for prompt content and formatting may be necessary\n",
      "to adapt our system to different underlying models. We believe that as increasingly capable LLMs\n",
      "become available in the future, the effectiveness of our methodology will also increase across various\n",
      "applications.\n",
      "Need for human assistance in certain tasks. Our formulation of self-improving agents allows\n",
      "agents to autonomously complete tasks through continuous re-prompting, as well as serve as inter-\n",
      "**************************************************\n",
      "{'source': 'Dataset/Practical Self-Improving Computer Agents.pdf', 'file_path': 'Dataset/Practical Self-Improving Computer Agents.pdf', 'page': 0, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'GPL Ghostscript 10.01.2', 'creationDate': \"D:20240418202537-04'00'\", 'modDate': \"D:20240418202537-04'00'\", 'trapped': ''}\n",
      "1\n",
      "Introduction\n",
      "Large Language Models (LLMs) pretrained on internet-scale data have been shown to develop some\n",
      "degree of emergent reasoning capabilities. This has enabled them to interact with tools and aug-\n",
      "mentations comprised of external software that interfaces with LLMs through their input and output\n",
      "pipelines. These pieces of external software may implement prompt engineering techniques, may\n",
      "be non-parametric, and have been associated with various different terminologies including \"aug-\n",
      "mentations,\" \"tools,\" and \"plugins.\" We view these various types of model-augmenting software to\n",
      "be expressions of the same overarching concept of model augmentation, which this paper aims to\n",
      "better understand and systematize. We introduce a practical methodology to automate the develop-\n",
      "ment of model-augmenting software by creating agents that can autonomously produce tools and\n",
      "augmentations to suit their own needs. These self-improving agents can then be used to ﬂexibly\n",
      "address diverse computer tasks, generating software to augment themselves and complete complex\n",
      "tasks that they are initially unable to solve.\n",
      "The following section provides an overview of the current state of research in large language mod-\n",
      "els, language model augmentations, and self-improving AI, highlighting the key contributions and\n",
      "developments in each area.\n",
      "1.1\n",
      "Large Language Models\n",
      "Foundation Models. The development of large language models has been a signiﬁcant area of\n",
      "**************************************************\n",
      "{'source': 'Dataset/Practical Self-Improving Computer Agents.pdf', 'file_path': 'Dataset/Practical Self-Improving Computer Agents.pdf', 'page': 21, 'total_pages': 25, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'GPL Ghostscript 10.01.2', 'creationDate': \"D:20240418202537-04'00'\", 'modDate': \"D:20240418202537-04'00'\", 'trapped': ''}\n",
      "in practical applications. In our experiments, we implement this system and demonstrate that our\n",
      "methodology is easy to use and ﬂexibly applicable to computer tasks. We show that a self-improving\n",
      "agent autonomously reproduces various augmentation techniques of interest in prior research.\n",
      "5.1\n",
      "Future Work\n",
      "Our work presents a number of promising directions for future research. We suggest a few areas\n",
      "where opportunities exist for exciting new ideas:\n",
      "• Application areas for self-improving computer agents and practical considerations.\n",
      "• Design improvements for algorithms, environment, and prompt engineering.\n",
      "• Practical and ethical risks of self-improving AI systems.\n",
      "We hope to spark interest in related research directions, and we are happy to collaborate or provide\n",
      "input on interesting new ideas.\n",
      "References\n",
      "Ari Biswas, Thai T Pham, Michael Vogelsong, Benjamin Snyder, and Houssam Nassif. Seeker: Real-time\n",
      "interactive search, 2019.\n",
      "Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S.\n",
      "Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas\n",
      "Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky,\n",
      "Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh,\n",
      "Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby Grossman,\n"
     ]
    }
   ],
   "source": [
    "for d in res['source_documents']:\n",
    "    print(\"*\"*50)\n",
    "    print(d.metadata)\n",
    "    print(d.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
